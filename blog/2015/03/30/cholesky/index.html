<!DOCTYPE HTML>
<html lang='en'>
<head>
<meta charset="utf-8">
<link rel="stylesheet" href="/style.css">
<link href='https://fonts.googleapis.com/css?family=Merriweather+Sans:400,400italic,700,700italic' rel='stylesheet' type='text/css'>
<link href='https://fonts.googleapis.com/css?family=Oranienbaum' rel='stylesheet' type='text/css'>

<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-6TPD9FMZC8"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  
  gtag('config', 'G-6TPD9FMZC8');
</script>
<meta content='nanoc 4.12.15' name='generator'>
<title>
Stumbling upon simplicity: the Cholesky decomposition
[Charles R. Hogg III]
</title>
</head>
<body>
<div id='title'>
<a title="Main page" href="/">Charles R. Hogg III</a>
<div id='nav'>
<ul>
<li>
<a title="About the author, the website, etc." href="/about/">About</a>
</li>
<li>
<a title="Personal blog" href="/blog/">Blog</a>
</li>
<li>
<a title="Things I&#39;m working on" href="/projects/">Projects</a>
</li>
<li>
<a title="Ways to contact me online" href="/contact/">Contact</a>
</li>
</ul>
</div>
</div>
<hr>
<div id='main'>
<div id='post'>
<h1>
Stumbling upon simplicity: the Cholesky decomposition
</h1>
<aside class='posted_at'>
Posted at 2015-03-30 23:06
</aside>
<aside class='tldr'>
<b>tl;dr:</b>
Sometimes things only seem complicated because we’ve never taken the time to play with them. Once I stopped treating the Cholesky decomposition as a black box, I found that it was surprisingly easy to compute.

</aside>
<article>
<p>The <a href="https://en.wikipedia.org/wiki/Cholesky_decomposition">Cholesky decomposition</a> is a key concept in matrix algebra. It’s a kind of “matrix square root”: a lower-triangular matrix <span class="math inline">\(L\)</span> which gives back the original matrix <span class="math inline">\(K\)</span> when multiplied with its transpose: <span class="math display">\[L L^\intercal = K.\]</span></p>
<p>It’s very useful for working with high-dimensional Gaussian distributions. <span class="math inline">\(L\)</span> takes independent one-dimensional Gaussian samples (i.e., the simplest possible case), and turns them into samples from the multidimensional distribution whose covariance matrix is <span class="math inline">\(K\)</span>.</p>
<p>For example, take the highly-correlated matrix <span class="math display">\[K = \left[\begin{array}{cc}1 &amp; 0.8 \\ 0.8 &amp; 1\end{array}\right].\]</span> Its Cholesky decomposition is <span class="math display">\[L = \left[\begin{array}{cc}1 &amp; 0 \\ 0.8 &amp; 0.6\end{array}\right],\]</span> as we can easily verify: <span class="math display">\[L L^\intercal = \left[\begin{array}{cc}1 &amp; 0 \\ 0.8 &amp; 0.6\end{array}\right] \left[\begin{array}{cc}1 &amp; 0.8 \\ 0 &amp; 0.6\end{array}\right] = \left[\begin{array}{cc}1 &amp; 0.8 \\ 0.8 &amp; 1\end{array}\right] = K.\]</span> If we now use <span class="math inline">\(L\)</span> to multiply <em>independent</em> normal samples, it turns them into <em>correlated</em> samples with a correlation of 0.8.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>num_points <span class="ot">&lt;-</span> <span class="dv">200</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>independent_random <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="at">nrow=</span><span class="dv">2</span>, <span class="fu">rnorm</span>(<span class="at">n=</span><span class="dv">2</span> <span class="sc">*</span> num_points))</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>correlated_random <span class="ot">&lt;-</span> L <span class="sc">%*%</span> independent_random</span></code></pre></div>
<p><img src="correlated_plot-1.png"></p>
<p>What’s missing in the above is any notion of how to <em>calculate</em> <span class="math inline">\(L\)</span>, given <span class="math inline">\(K\)</span>. If we have a good software library, we can just use it, and treat this calculation as a black box. But if we want to dig deeper, we’re in luck: it turns out we already have enough information to compute it from scratch.</p>
<p>Everything here is elementary, and I’m sure it’s quite well known. I’m only blogging it to share my utter delight when I stumbled across its underlying simplicity.</p>
<h2 id="adding-one-more-row">Adding “one more row”</h2>
<p>In the appendix for <a href="https://github.com/chiphogg/paper_gaussian_oscillators">my animation paper</a>, I asked the question: given <span class="math inline">\(n\)</span> draws from a Gaussian with a particular covariance function, can we efficiently compute the <span class="math inline">\((n+1)\)</span>st?</p>
<p>If we have the first <span class="math inline">\(n\)</span> draws, that means we have their covariance matrix <span class="math inline">\(K_n\)</span> and its Cholesky decomposition <span class="math inline">\(L_n\)</span>, so that <span class="math inline">\(L_n L_n^\intercal = K_n\)</span>. We also have the covariance of every old point with the new point, a vector we’ll call <span class="math inline">\(k_n\)</span>, as well as the new point’s variance <span class="math inline">\(\sigma_{n + 1}^2\)</span>. Together, these form the new covariance matrix<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>, <span class="math display">\[ K_{n + 1} =
\left[\begin{array}{cc}
K_n &amp; k_n \\
k_n^\intercal &amp; \sigma_{n + 1}^2
\end{array}\right]
\]</span></p>
<p>What we <em>need</em> is the new row that makes <span class="math inline">\(L_n\)</span> into <span class="math inline">\(L_{n + 1}\)</span>, where <span class="math inline">\(L_{n + 1} L_{n + 1}^\intercal = K_{n + 1}\)</span>. We can break this row into two pieces: a vector <span class="math inline">\(\ell_n^\intercal\)</span> (corresponding to contributions from all the old points), and a scalar <span class="math inline">\(\gamma_{n + 1}\)</span> (corresponding to the new point). This gives us a block matrix equation: <span class="math display">\[
\left[\begin{array}{cc}
L_n &amp; 0 \\
\ell_n^\intercal &amp; \gamma_{n + 1}
\end{array}\right]
\left[\begin{array}{cc}
L_n^\intercal &amp; \ell_n \\
0 &amp; \gamma_{n + 1}
\end{array}\right]
= \left[\begin{array}{cc}
K_n &amp; k_n \\
k_n^\intercal &amp; \sigma_{n + 1}^2
\end{array}\right]
\]</span> What interesting equations fall out of this?</p>
<ol type="1">
<li><span class="math inline">\(L_n L_n^\intercal = K_n\)</span></li>
</ol>
<ul>
<li>Well, we knew that already.</li>
</ul>
<ol start="2" type="1">
<li><span class="math inline">\(L_n \ell_n = k_n\)</span></li>
</ol>
<ul>
<li>
<p>Now, this looks promising! <span class="math inline">\(L_n\)</span> and <span class="math inline">\(k_n\)</span> are known, so we can solve for <span class="math inline">\(\ell_n\)</span>.</p>
<p>It gets better: remember that <span class="math inline">\(L_n\)</span> is lower-triangular, so the equation looks something like this: <span class="math display">\[
\left[\begin{array}{cccc}
L_{11} &amp; 0 &amp; 0 &amp; \cdots \\
L_{21} &amp; L_{22} &amp; 0 &amp; \cdots \\
L_{31} &amp; L_{32} &amp; L_{33} &amp; \cdots \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots \\
\end{array}\right]
\left[\begin{array}{c}
\ell_1 \\
\ell_2 \\
\ell_3 \\
\vdots
\end{array}\right]
= \left[\begin{array}{c}
k_1 \\
k_2 \\
k_3 \\
\vdots
\end{array}\right]
\]</span> (Everything is known except the <span class="math inline">\(\ell\)</span>s.)</p>
<p>In the first row, <span class="math inline">\(\ell_1\)</span> is the only unknown; we have <span class="math inline">\(\ell_1 = k_1 / L_{11}\)</span>. The second row uses only <span class="math inline">\(\ell_1\)</span> and <span class="math inline">\(\ell_2\)</span>, but we already solved for <span class="math inline">\(\ell_1\)</span>: again, only one unknown, which is easy to solve.</p>
<p>Going down the line, we can solve for every element of <span class="math inline">\(\ell\)</span>, without even doing any matrix manipulations.</p>
</li>
</ul>
<ol start="3" type="1">
<li><span class="math inline">\(\ell_n^\intercal \ell_n + \gamma_{n + 1}^2 = \sigma_{n + 1} ^ 2\)</span></li>
</ol>
<ul>
<li>Since we already figured out <span class="math inline">\(\ell_n\)</span> above, and we know <span class="math inline">\(\sigma_{n + 1}\)</span>, this equation is just as easy as the previous ones.</li>
</ul>
<p>So: yes, we <em>can</em> compute the next row of the Cholesky decomposition if we know all the previous rows.</p>
<h2 id="this-smells-like-induction">This smells like induction</h2>
<p>We now know how to get <span class="math inline">\(L_{n + 1}\)</span> if we have <span class="math inline">\(L_n\)</span>, but how do we get <span class="math inline">\(L_n\)</span> in the first place? One way is to call a library function—always a good default strategy. This works pretty well, until <a href="https://github.com/jstat/jstat/blob/b3a72f52917403e948f628dfebd645f8cb925c52/src/linearalgebra.js#L284-L286">it doesn’t</a>.</p>
<p>Another approach would be to start with <span class="math inline">\(L_{n - 1}\)</span>, and use what we just figured out to add the final row. Of course, then we’d <em>need</em> <span class="math inline">\(L_{n - 1}\)</span>, but we could get it from <span class="math inline">\(L_{n - 2}\)</span>…</p>
<p>At this point, I’m reminded of <a href="https://en.wikipedia.org/wiki/Mathematical_induction">mathematical induction</a>: a method to generate “valid for any positive integer” proofs based on two ingredients. One ingredient is a method for getting from step <span class="math inline">\(n\)</span> to step <span class="math inline">\((n + 1)\)</span> for any <span class="math inline">\(n\)</span>; we have that already. The other ingredient is a <em>base case</em>: an answer for the smallest possible <span class="math inline">\(n\)</span> which <em>doesn’t</em> depend on any earlier stages.</p>
<p>In our case, the base case turns out to be trivial. The simplest matrix which could have a Cholesky decomposition is a <span class="math inline">\((1 \times 1)\)</span> matrix; let’s say <span class="math inline">\(K = \left[ k \right]\)</span> for some <span class="math inline">\(k &gt; 0\)</span>. Then <span class="math inline">\(L = \left[ \sqrt{k} \right]\)</span>—what could be easier!</p>
<p>We can put this all together to compute the elements of <span class="math inline">\(L\)</span> one at a time. Each new element uses <span class="math inline">\(K\)</span> and the elements of <span class="math inline">\(L\)</span> we’ve <em>already</em> computed. Let’s update our notation for consistency: we’ll replace the <span class="math inline">\(\ell\)</span>s and <span class="math inline">\(k\)</span>s with the corresponding indices in <span class="math inline">\(L\)</span> and <span class="math inline">\(K\)</span>. The matrix equation for a typical intermediate stage looks like this: <span class="math display">\[
\left[\begin{array}{cc}
  L_{11} &amp; 0 \\
  L_{21} &amp; L_{22}
\end{array}\right]
\left[\begin{array}{c} L_{31} \\ L_{32} \end{array}\right]
= \left[ \begin{array}{c} K_{31} \\ K_{32} \end{array} \right]
.\]</span> This gives us the “pre-diagonal” elements of the third row, <span class="math inline">\(L_{31}\)</span> and <span class="math inline">\(L_{32}\)</span>. We’ll then get <span class="math inline">\(L_{33}\)</span> in terms of <span class="math inline">\(K_{33}\)</span> and these same pre-diagonal elements, and this gives us everything we’ll need to compute the <em>fourth</em> row. So it goes, until we have the whole matrix.</p>
<p>I started out trying to extend existing Cholesky matrices, and I got the ability to compute <em>any</em> Cholesky matrix thrown in for free.</p>
<h2 id="testing-it-out">Testing it out</h2>
<p>Let’s turn these ideas into actual code.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># This doesn't check that K actually *has* a Cholesky decomposition (not every</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co"># matrix does).  Give it some garbage, and it will happily return a nonsense</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># answer (if it doesn't crash first!).</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co"># That's OK; the point is to see if it gives the right answer for suitable</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co"># matrices.</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co"># For this reason (and many others!), you shouldn't be using this algorithm in</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co"># the real world: like the blog post it's part of, it's only good for improving</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co"># your understanding of the concept.</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>MyCholesky <span class="ot">&lt;-</span> <span class="cf">function</span>(K) {</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">nrow</span>(K)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Start out with a matrix which is all zeroes, except for the upper-left</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>  <span class="co"># element.  (We know that element is the square root of the corresponding</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>  <span class="co"># element in K, since that's the base case.)</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>  L <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, <span class="at">nrow=</span>n, <span class="at">ncol=</span>n)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>  L[<span class="dv">1</span>, <span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(K[<span class="dv">1</span>, <span class="dv">1</span>])</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (n <span class="sc">==</span> <span class="dv">1</span>) { <span class="fu">return</span>(L) }</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute each row's values.</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (row <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span>n) {</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># This loop computes all the elements *before* the diagonal (which</span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># corresponds to step 2 above).</span></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (col <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>(row <span class="sc">-</span> <span class="dv">1</span>)) {</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>      <span class="co"># sum_to_subtract is the contribution of the elements we've previously</span></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>      <span class="co"># computed in this new row.</span></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>      sum_to_subtract <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> (col <span class="sc">&gt;</span> <span class="dv">1</span>) {</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>        i <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span>(col <span class="sc">-</span> <span class="dv">1</span>)</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>        sum_to_subtract <span class="ot">&lt;-</span> L[col, i] <span class="sc">%*%</span> L[row, i]</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>      L[row, col] <span class="ot">&lt;-</span> (K[row, col] <span class="sc">-</span> sum_to_subtract) <span class="sc">/</span> L[col, col]</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Now compute the element on the main diagonal (corresponding to step 3</span></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># above).</span></span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>    i <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span>(row <span class="sc">-</span> <span class="dv">1</span>)</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>    L[row, row] <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(K[row, row] <span class="sc">-</span> L[row, i] <span class="sc">%*%</span> L[row, i])</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span> (L)</span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>To test this, I’ll construct a random <span class="math inline">\((20 \times 20)\)</span> covariance matrix. I’ll compute its Cholesky decomposition twice—once with my method, and once with R’s built-in <code>chol()</code> function—and see how close the two answers are.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate some points.</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">sort</span>(<span class="fu">rnorm</span>(<span class="at">n=</span>N))</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Construct a matrix from a covariance function which I know is valid.</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co"># (We'll add some noise on the diagonal to help it converge).</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>K <span class="ot">&lt;-</span> <span class="fu">outer</span>(x, x,</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>           <span class="cf">function</span>(a, b) {</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>             <span class="fu">exp</span>(<span class="sc">-</span>(a <span class="sc">-</span> b)<span class="sc">^</span><span class="dv">2</span>) <span class="sc">+</span> <span class="fu">ifelse</span>(a<span class="sc">==</span>b, <span class="fl">0.01</span>, <span class="fl">0.0</span>)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>           })</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="co"># What are the biggest and smallest differences between my method,</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="co"># and R's built-in method I know is correct?</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="fu">range</span>(<span class="fu">MyCholesky</span>(K) <span class="sc">-</span> <span class="fu">t</span>(<span class="fu">chol</span>(K)))</span></code></pre></div>
<pre><code>## [1] -1.915135e-15  2.720046e-15</code></pre>
<p>So the biggest difference was smaller than <span class="math inline">\(10^{-14}\)</span>. Looks pretty good to me!</p>
<h2 id="conclusions">Conclusions</h2>
<p>Don’t be intimidated by theorems with <a href="https://biostat-lists.wustl.edu/sympa/arc/s-news/2000-10/msg00172.html">hard to pronounce</a> names. They often contain extremely simple ideas.</p>
<aside id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Note that this is a <a href="https://en.wikipedia.org/wiki/Block_matrix">block matrix</a>: one whose elements stand for other matrices. Specifically, <span class="math inline">\(K_n\)</span> is an <span class="math inline">\((n \times n)\)</span> matrix; <span class="math inline">\(k_n\)</span> is <span class="math inline">\((n \times 1)\)</span> (i.e., a vector), and <span class="math inline">\(\sigma_{n + 1}^2\)</span> is <span class="math inline">\((1 \times 1)\)</span> (i.e., a scalar).<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</aside>

</article>
</div>

</div>
<div id='source'>
<a href='https://github.com/chiphogg/chogg_name/tree/master/content/blog/cholesky.Rmd'>
Page source on GitHub
</a>
</div>
</body>
</html>
